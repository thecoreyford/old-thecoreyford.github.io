---
---
@string{aps = {American Physical Society,}}
@inproceedings{NIME21_18,
  abbr={NIME},
  author = {Ford, Corey and Bryan-Kinns, Nick and Nash, Chris},
  title = {Creativity in Children's Digital Music Composition},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  year = {2021},
  month = jun,
  address = {Shanghai, China},
  issn = {2220-4806},
  articleno = {18},
  doi = {10.21428/92fbeb44.e83deee9},
  url = {https://nime.pubpub.org/pub/ker5w948},
  pdf = {https://nime.pubpub.org/pub/ker5w948},
  presentation-video = {https://youtu.be/XpMiDWrxXMU},
  selected = {true},
  kind={Conference},
  abstract={Composing is a neglected area of music education. To increase participation, many technologies provide open-ended interfaces to motivate child autodidactic use, drawing influence from Papert’s LOGO philosophy to support children’s learning through play. This paper presents a case study examining which interactions with Codetta, a LOGO-inspired, block-based music platform, supports children’s creativity in music composition. Interaction logs were collected from 20 children and correlated against socially-validated creativity scores. To conclude, we recommend that the transition between low-level edits and high-level processes should be carefully scaffolded.}
}

@inproceedings{NIME20_53,
  abbr={NIME},
  author = {Ford, Corey and Nash, Chris},
  title = {An Iterative Design ‘by proxy’ Method for Developing Educational Music Interfaces},
  pages = {279--284},
  booktitle = {Proceedings of the International Conference on New Interfaces for Musical Expression},
  editor = {Michon, Romain and Schroeder, Franziska},
  year = {2020},
  month = jul,
  kind={Conference},
  publisher = {Birmingham City University},
  address = {Birmingham, UK},
  issn = {2220-4806},
  doi = {10.5281/zenodo.4813361},
  url = {https://www.nime.org/proceedings/2020/nime2020_paper53.pdf},
  pdf = {https://www.nime.org/proceedings/2020/nime2020_paper53.pdf},
  presentation-video = {https://youtu.be/fPbZMQ5LEmk},
  abstract={Iterative design methods involving children and educators are difficult to conduct, given both the ethical implications and time commitments understandably required. The qualitative design process presented here recruits introductory teacher training students, towards discovering useful design insights relevant to music education technologies “by proxy”. Therefore, some of the barriers present in child-computer interaction research are avoided. As an example, the method is applied to the creation of a block-based music notation system, named Codetta. Building upon successful educational technologies that intersect both music and computer programming, Codetta seeks to enable child composition, whilst aiding generalist educator’s confidence in teaching music.},
}

@inproceedings{XAI4Debugging,
  abbr={XAI @ NeurIPS},
  author = {Bryan-Kinns, Nick and Banar, Berker and Ford, Corey and Reed, Courtney N. and Zhang, Yixiao and Colton, Simon and Armitage, Jack},
  title = {Exploring XAI for the Arts: Explaining Latent Space in Generative Music},
  pages = {14},
  booktitle = {1st Workshop on eXplainable AI Approaches for Debugging and Diagnosis (XAI4Debugging@NeurIPS2021)},
  year = {2021},
  month = dec,
  kind={Workshop},
  url = {https://xai4debugging.github.io/files/papers/exploring_xai_for_the_arts_exp.pdf},
  pdf = {https://xai4debugging.github.io/files/papers/exploring_xai_for_the_arts_exp.pdf},
  abstract={Explainable AI has the potential to support more interactive and fluid co-creative AI systems which can creatively collaborate with people. To do this, creative AI models need to be amenable to debugging by offering eXplainable AI (XAI) features which are inspectable, understandable, and modifiable. However, currently there is very little XAI for the arts. In this work, we demonstrate how a latent variable model for music generation can be made more explainable; specifically we extend MeasureVAE which generates measures of music. We increase the explainability of the model by: i) using latent space regularisation to force some specific dimensions of the latent space to map to meaningful musical attributes, ii) providing a user interface feedback loop to allow people to adjust dimensions of the latent space and observe the results of these changes in real-time, iii) providing a visualisation of the musical attributes in the latent space to help people understand and predict the effect of changes to latent space dimensions. We suggest that in doing so we bridge the gap between the latent space and the generated musical outcomes in a meaningful way which makes the model and its outputs more explainable and more debuggable. 
  The code repository can be found at: https://github.com/bbanar2/Exploring_XAI_in_GenMus_via_LSR},
}